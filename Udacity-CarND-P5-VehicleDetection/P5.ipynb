{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from random import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Project parameters\n",
    "TEST_IMGS_PATH = \"./test_images\"\n",
    "OUTPUT_IMGS_PATH = \"./output_images\"\n",
    "MODEL_PATH = \"model.pkl\"\n",
    "TEST_VIDEO_PATH = './test_video.mp4'\n",
    "PROJECT_VIDEO_PATH = './project_video.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load images\n",
    "test_imgs = []\n",
    "for img_f in glob(os.path.join(TEST_IMGS_PATH, \"*.jpg\")):\n",
    "    test_imgs.append(mpimg.imread(img_f))\n",
    "\n",
    "non_vehicle_imgs = []\n",
    "for img_f in glob(os.path.join(TEST_IMGS_PATH, \"non-vehicles/**/*.png\")):\n",
    "    non_vehicle_imgs.append(mpimg.imread(img_f))\n",
    "    \n",
    "vehicle_imgs = []\n",
    "for img_f in glob(os.path.join(TEST_IMGS_PATH, \"vehicles/**/*.png\")):\n",
    "    vehicle_imgs.append(mpimg.imread(img_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total number of test images: {}\".format(len(test_imgs)))\n",
    "print(\"total number of non-vehicle images: {}\".format(len(non_vehicle_imgs)))\n",
    "print(\"total number of vehicle images: {}\".format(len(vehicle_imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "def convert_color(img, color_space):\n",
    "    if \"RGB\" != color_space:\n",
    "        return cv2.cvtColor(img, getattr(cv2, \"COLOR_RGB2{}\".format(color_space)))\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def show_color_space(img, color_space=\"RGB\"):\n",
    "    \"\"\"Explores the distribution of color values.\"\"\"\n",
    "    \n",
    "    # Select a small fraction of pixels to plot by subsampling it\n",
    "    scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "    img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "    img_small_rgb = img_small / 255.\n",
    "    img_small = convert_color(img_small, color_space)\n",
    "    \n",
    "    plot3d(img_small, img_small_rgb, axis_labels=list(color_space) if color_space != 'YCrCb' else ['Y','Cr','Cb'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_img = cv2.cvtColor(\n",
    "    cv2.imread(os.path.join(TEST_IMGS_PATH, 'vehicles/KITTI_extracted/444.png')), \n",
    "              cv2.COLOR_BGR2RGB)\n",
    "non_vehicle_img = cv2.cvtColor(\n",
    "    cv2.imread(os.path.join(TEST_IMGS_PATH, 'non-vehicles/Extras/extra40.png')),\n",
    "              cv2.COLOR_BGR2RGB)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(vehicle_img)\n",
    "ax1.set_title('Example Car Image')\n",
    "ax2.imshow(non_vehicle_img)\n",
    "ax2.set_title('Example Non Car Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_space(vehicle_img)\n",
    "show_color_space(non_vehicle_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_space(vehicle_img, \"HSV\")\n",
    "show_color_space(non_vehicle_img, \"HSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_space(vehicle_img, \"YUV\")\n",
    "show_color_space(non_vehicle_img, \"YUV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_space(vehicle_img, \"YCrCb\")\n",
    "show_color_space(non_vehicle_img, \"YCrCb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, color_space='RGB', nbins=32, bins_range=(0, 256)):\n",
    "    \"\"\"Extracts color histogram features.\"\"\"\n",
    "    img = convert_color(img, color_space) / 255 * (bins_range[1] - bins_range[0])\n",
    "    \n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_feat = color_hist(vehicle_img, color_space=\"YUV\", bins_range=(0, 1))\n",
    "non_vehicle_feat = color_hist(non_vehicle_img, color_space=\"YUV\", bins_range=(0, 1))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(vehicle_feat, label='vehicle')\n",
    "plt.plot(non_vehicle_feat, label='non-vehicle')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, color_space='RGB', size=(32, 32)):\n",
    "    \"\"\"Coverts image to one dimensional feature vector of specific color space.\"\"\"\n",
    "    # Convert image to new color space (if specified)\n",
    "    if color_space != 'RGB':\n",
    "        feature_image = cv2.cvtColor(img, getattr(cv2, \"COLOR_RGB2{}\".format(color_space)))\n",
    "    else: feature_image = np.copy(img)             \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(feature_image, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle feature vector vs non vehicle feature vecture\n",
    "vehicle_feat = bin_spatial(vehicle_img, color_space=\"YUV\", size=(32, 32))\n",
    "non_vehicle_feat = bin_spatial(non_vehicle_img, color_space=\"YUV\", size=(32, 32))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(vehicle_feat, label='vehicle')\n",
    "plt.plot(non_vehicle_feat, label='non-vehicle')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Histogram of Oriented Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient=9, pix_per_cell=8, cell_per_block=2, vis=False, feature_vec=True):\n",
    "    \"\"\"Extracts HOG features and generates visualization.\"\"\"\n",
    "    \n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(vehicle_img, cv2.COLOR_RGB2GRAY)\n",
    "features, hog_image = get_hog_features(gray, vis=True, feature_vec=False)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(gray, cmap='gray')\n",
    "ax1.set_title('Example Car Image')\n",
    "ax2.imshow(hog_image, cmap='gray')\n",
    "ax2.set_title('HOG Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_img = convert_color(vehicle_img, 'YCrCb')\n",
    "\n",
    "for c in range(converted_img.shape[2]):\n",
    "    ch = converted_img[:,:,c]\n",
    "    features, hog_image = get_hog_features(ch, vis=True, feature_vec=False)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(ch, cmap='gray')\n",
    "    ax1.set_title('Example Car Image')\n",
    "    ax2.imshow(hog_image, cmap='gray')\n",
    "    ax2.set_title('HOG Visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_img = convert_color(non_vehicle_img, 'YCrCb')\n",
    "\n",
    "for c in range(converted_img.shape[2]):\n",
    "    ch = converted_img[:,:,c]\n",
    "    features, hog_image = get_hog_features(ch, vis=True, feature_vec=False)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(ch, cmap='gray')\n",
    "    ax1.set_title('Example Non Car Image')\n",
    "    ax2.imshow(hog_image, cmap='gray')\n",
    "    ax2.set_title('HOG Visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Image Classifier\n",
    "## Combine and Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, flip_rate=0.0, cs_list=['YUV', 'YUV', 'YCrCb'], \n",
    "                     nbins=32, bins_range=(0, 256),\n",
    "                     spatial_size=(32, 32),\n",
    "                     hog_channels=[0,1,2], orient=9, pix_per_cell=8, cell_per_block=2,\n",
    "                     hist_feat=True, spatial_feat=True, hog_feat=True):\n",
    "    \"\"\"\n",
    "    It extracts desired features from images.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    augment_imgs = []\n",
    "    \n",
    "    for img in imgs:\n",
    "        hist_features = []\n",
    "        spatial_features = []\n",
    "        hog_features = []\n",
    "        \n",
    "        if hist_feat:\n",
    "            hist_features = color_hist(img, color_space=cs_list[0], nbins=nbins, bins_range=bins_range)\n",
    "        \n",
    "        if spatial_feat:\n",
    "            spatial_features = bin_spatial(img, color_space=cs_list[1], size=spatial_size)\n",
    "        \n",
    "        if hog_feat:\n",
    "            converted_img = convert_color(img, cs_list[2])\n",
    "            \n",
    "            hog_feats = []\n",
    "            for c in hog_channels:\n",
    "                ch = converted_img[:,:,c]\n",
    "                hog_feats.append(get_hog_features(ch, orient, \n",
    "                                                  pix_per_cell, cell_per_block,\n",
    "                                                  feature_vec=True))\n",
    "            hog_features = np.ravel(hog_feats)\n",
    "        \n",
    "        features.append(np.hstack((hist_features, spatial_features, hog_features)))\n",
    "    \n",
    "        # augment data by fliping at a certain rate that is smaller than 1.0 (duplicate)\n",
    "        if random() < flip_rate:\n",
    "            augment_imgs.append(cv2.flip(img, 0))\n",
    "    \n",
    "    if ([] != augment_imgs):\n",
    "        # add features from augment data\n",
    "        augment_features = extract_features(augment_imgs, cs_list=cs_list,\n",
    "                                            nbins=nbins, bins_range=bins_range,\n",
    "                                            spatial_size=spatial_size, \n",
    "                                            orient=orient, \n",
    "                                            pix_per_cell=pix_per_cell, \n",
    "                                            cell_per_block=cell_per_block,\n",
    "                                            hist_feat=hist_feat, \n",
    "                                            spatial_feat=spatial_feat, \n",
    "                                            hog_feat=hog_feat)\n",
    "        features.extend(augment_features)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list=['YUV', 'YUV', 'YCrCb']\n",
    "nbins=32\n",
    "bins_range=(0,1)\n",
    "spatial_size=(32,32)\n",
    "hog_channels=[0,1,2]\n",
    "orient=9\n",
    "pix_per_cell=8\n",
    "cell_per_block=2\n",
    "hist_feat=True\n",
    "spatial_feat=True\n",
    "hog_feat=True\n",
    "\n",
    "car_features = extract_features(vehicle_imgs, \n",
    "                                nbins=nbins, bins_range=bins_range,\n",
    "                                spatial_size=spatial_size,\n",
    "                                hog_channels=hog_channels,\n",
    "                                orient=orient, \n",
    "                                pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block,\n",
    "                                hist_feat=hist_feat, \n",
    "                                spatial_feat=spatial_feat, \n",
    "                                hog_feat=hog_feat)\n",
    "non_car_features = extract_features(non_vehicle_imgs,\n",
    "                                    nbins=nbins, bins_range=bins_range,\n",
    "                                    spatial_size=spatial_size,\n",
    "                                    hog_channels=hog_channels,\n",
    "                                    orient=orient, \n",
    "                                    pix_per_cell=pix_per_cell, \n",
    "                                    cell_per_block=cell_per_block,\n",
    "                                    hist_feat=hist_feat, \n",
    "                                    spatial_feat=spatial_feat, \n",
    "                                    hog_feat=hog_feat)\n",
    "\n",
    "print(\"Total number of vehicle features: {}\".format(len(car_features)))\n",
    "print(\"Total number of non vehicle features: {}\".format(len(non_car_features)))\n",
    "\n",
    "if len(car_features) > 0:\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, non_car_features)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    car_ind = np.random.randint(0, len(vehicle_imgs))\n",
    "    # Plot an example of raw and scaled features\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(vehicle_imgs[car_ind])\n",
    "    plt.title('Original Image')\n",
    "    plt.subplot(132)\n",
    "    plt.plot(X[car_ind])\n",
    "    plt.title('Raw Features')\n",
    "    plt.subplot(133)\n",
    "    plt.plot(scaled_X[car_ind])\n",
    "    plt.title('Normalized Features')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    non_car_ind = np.random.randint(0, len(non_vehicle_imgs))\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(non_vehicle_imgs[non_car_ind])\n",
    "    plt.title('Original Image')\n",
    "    plt.subplot(132)\n",
    "    plt.plot(X[len(non_vehicle_imgs) + non_car_ind])\n",
    "    plt.title('Raw Features')\n",
    "    plt.subplot(133)\n",
    "    plt.plot(scaled_X[len(non_vehicle_imgs) + non_car_ind])\n",
    "    plt.title('Normalized Features')\n",
    "    fig.tight_layout()\n",
    "else: \n",
    "    print('Your function only returns empty feature vectors...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total of {} features\".format(len(car_features[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(non_car_features))))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[0.1, 1, 10]}\n",
    "svr = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t = time.time()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "clf.fit(X_scaler.transform(X_train), y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "print('Training Accuracy = ', round(clf.score(X_scaler.transform(X_train), y_train), 4))\n",
    "print('Validation Accuracy = ', round(clf.score(X_scaler.transform(X_val), y_val), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: {}\".format(clf.best_params_))\n",
    "\n",
    "model = {\n",
    "    \"cs_list\": ['YUV', 'YUV', 'YCrCb'],\n",
    "    \"nbins\": 32,\n",
    "    \"bins_range\": (0,1),\n",
    "    \"spatial_size\": (32,32),\n",
    "    \"hog_channels\": [0,1,2],\n",
    "    \"orient\": 9,\n",
    "    \"pix_per_cell\": 8,\n",
    "    \"cell_per_block\": 2,\n",
    "    \"hist_feat\": True,\n",
    "    \"spatial_feat\": True,\n",
    "    \"hog_feat\": True,\n",
    "    \"X_scaler\": X_scaler,\n",
    "    \"clf\": clf\n",
    "}\n",
    "\n",
    "# Store dataset for more runs\n",
    "with open(MODEL_PATH, 'wb') as pkl_file:\n",
    "    pickle.dump(model, pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hog Sub-sampling Window Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    \"\"\"\n",
    "    A helper function for drawing detection boxes on image.\n",
    "    \"\"\"\n",
    "    imcopy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "\n",
    "def find_cars(img, ystart, ystop, scale, X_scaler, clf,\n",
    "              window_xy=(64, 64), cells_per_step=2,\n",
    "              cs_list=['YUV', 'YUV', 'YCrCb'],\n",
    "              hist_bins=32, bins_range=(0,1),\n",
    "              spatial_size=(32,32),\n",
    "              hog_channels=[0,1,2],\n",
    "              orient=9, \n",
    "              pix_per_cell=8, \n",
    "              cell_per_block=2):\n",
    "    \"\"\"\n",
    "    Applys trained classifier on sliding windows to return windows in which\n",
    "    car is detected.\n",
    "    Feature extraction of each sliding windows is using Hog Sub-sampling.\n",
    "    \"\"\"\n",
    "    heat_windows = []\n",
    "    # as we trained with images contains value (0, 1), we need to make sure\n",
    "    # input image also contains value (0, 1)\n",
    "    img = img.astype(np.float32) / 255\n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    \n",
    "    # Extract HOG features for the entire search part\n",
    "    hog_tosearch = convert_color(img_tosearch, cs_list[2])\n",
    "    if scale != 1:\n",
    "        imshape = hog_tosearch.shape\n",
    "        hog_tosearch = cv2.resize(hog_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "    \n",
    "    ch1 = hog_tosearch[:,:,0]\n",
    "    ch2 = hog_tosearch[:,:,1]\n",
    "    ch3 = hog_tosearch[:,:,2]\n",
    "    \n",
    "    ## Define blocks and steps as above\n",
    "    nxblocks = (hog_tosearch.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (hog_tosearch.shape[0] // pix_per_cell) - cell_per_block + 1\n",
    "    window_x_blocks = window_xy[1] // pix_per_cell - cell_per_block + 1\n",
    "    window_y_blocks = window_xy[0] // pix_per_cell - cell_per_block + 1\n",
    "    nxsteps = (nxblocks - window_x_blocks) // cells_per_step\n",
    "    nysteps = (nyblocks - window_y_blocks) // cells_per_step\n",
    "    \n",
    "    ## Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+window_y_blocks, xpos:xpos+window_x_blocks].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+window_y_blocks, xpos:xpos+window_x_blocks].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+window_y_blocks, xpos:xpos+window_x_blocks].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(img_tosearch[ytop:ytop+window_xy[0], xleft:xleft+window_xy[1]], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            hist_features = color_hist(subimg, color_space=cs_list[0], nbins=hist_bins, bins_range=bins_range)\n",
    "            spatial_features = bin_spatial(subimg, color_space=cs_list[1], size=spatial_size)\n",
    "            \n",
    "            # Scale features and make a prediction\n",
    "            features = X_scaler.transform(np.hstack((hist_features, spatial_features, hog_features)).reshape(1, -1))    \n",
    "            prediction = clf.predict(features)\n",
    "            \n",
    "            if prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                xwin_draw = np.int(window_xy[0]*scale)\n",
    "                ywin_draw = np.int(window_xy[1]*scale)\n",
    "                heat_windows.append(((xbox_left, ytop_draw+ystart), (xbox_left+xwin_draw, ytop_draw+ywin_draw+ystart)))\n",
    "            \n",
    "    return heat_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1.5\n",
    "\n",
    "heat_windows = find_cars(test_imgs[4], ystart, ystop, scale, X_scaler, clf)\n",
    "out_img = draw_boxes(test_imgs[4], heat_windows)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1\n",
    "\n",
    "heat_windows = find_cars(test_imgs[2], ystart, ystop, scale, X_scaler, clf)\n",
    "out_img = draw_boxes(test_imgs[2], heat_windows)\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, heat_windows):\n",
    "    \"\"\"Generates a heatmamp based on detected windows.\"\"\"\n",
    "    # Iterate through list of bboxes\n",
    "    for w in heat_windows:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[w[0][1]:w[1][1], w[0][0]:w[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    \"\"\"Generates a thresholds heatmap.\"\"\"\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    \"\"\"Draw bounding boxes around labels.\"\"\"\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.zeros(test_imgs[4].shape)\n",
    "heatmap = add_heat(heatmap, heat_windows)\n",
    "thresh_heatmap = apply_threshold(heatmap, 2)\n",
    "labels = label(thresh_heatmap)\n",
    "print(labels[1], ' cars found')\n",
    "plt.imshow(draw_labeled_bboxes(test_imgs[4], labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH, 'rb') as pkl_file:\n",
    "    model = pickle.load(pkl_file)\n",
    "\n",
    "X_scaler = model[\"X_scaler\"]\n",
    "clf = model[\"clf\"]\n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = [1, 1.5, 2]\n",
    "heap_threshold = 3\n",
    "frame_count = 0\n",
    "label_freq = 6 # Generate labels for every 6 frames\n",
    "pre_heat_windows = []\n",
    "pre_labels = ([], 0)\n",
    "\n",
    "def car_detector(img):\n",
    "    \"\"\"Car detection pipeline.\"\"\"\n",
    "    global frame_count\n",
    "    global pre_heat_windows\n",
    "    global pre_labels\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    for scl in scale:\n",
    "        pre_heat_windows.extend(find_cars(img, ystart, ystop, scl, X_scaler, clf))\n",
    "    \n",
    "    if frame_count >= label_freq:\n",
    "        heatmap = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "        heatmap = add_heat(heatmap, pre_heat_windows)\n",
    "        thresh_heatmap = apply_threshold(heatmap, heap_threshold)\n",
    "        labels = label(thresh_heatmap)\n",
    "        \n",
    "        if labels[1] > 0:\n",
    "            pre_labels = labels\n",
    "        \n",
    "        # clean up previous heat windows and frame count\n",
    "        del pre_heat_windows[:]\n",
    "        frame_count = 0\n",
    "\n",
    "    draw_labeled_bboxes(img, pre_labels)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./test.mp4\n",
      "[MoviePy] Writing video ./test.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████████▉  | 38/39 [00:41<00:01,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./test.mp4 \n",
      "\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "test_output = './test.mp4'\n",
    "clip = VideoFileClip(TEST_VIDEO_PATH)\n",
    "test_clip = clip.fl_image(car_detector)\n",
    "%time test_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./project_result.mp4\n",
      "[MoviePy] Writing video ./project_result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████▉| 1260/1261 [22:17<00:01,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_result.mp4 \n",
      "\n",
      "Wall time: 22min 18s\n"
     ]
    }
   ],
   "source": [
    "pre_heat_windows = []\n",
    "pre_labels = ([], 0)\n",
    "project_output = './project_result.mp4'\n",
    "clip = VideoFileClip(PROJECT_VIDEO_PATH)\n",
    "project_clip = clip.fl_image(car_detector)\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
